import uuid
from typing import Literal

from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage
from pydantic import BaseModel, Field

from app.services.llm import _get_model
from app.tools.retrieval_tool import retrieval_tool
from app.tools.web_search_tool import web_search as web_search_tool
from app.agents.react_agent_v2.state import AgentState


class GradeRetrieval(BaseModel):
    """Binary score for relevance check on retrieved documents."""
    score: Literal["yes", "no"] = Field(
        description="Information is relevant and sufficient to answer the user query: 'yes' or 'no'"
    )

class SearchQuery(BaseModel):
    """The refined search query."""
    query: str = Field(description="A specific, targeted web search query")
 
class LLMOutput(BaseModel):
    """The final response generated by the LLM."""
    content: str = Field(description="the LLM's plain textual response to user's query")   
def parse_query_node(state: AgentState) -> AgentState:
    print("parsing user query")
    messages = state.get("messages", [])

    if messages and isinstance(messages[-1], HumanMessage):
        user_query = messages[-1].content
    else:
        user_query = state.get("user_query", "")

    return {
        **state,
        "user_query": user_query,
        "retrieval_done": False,
        "web_search_done": False,
        "needs_web_search": False,
        "iteration_count": 0,
        "retrieval_results": "",
        "web_search_results": "",
        "final_response": "",
        "search_query": user_query
    }


def retrieval_node(state: AgentState) -> AgentState:
    print("retrieving from knowledge base")
    query = state["user_query"]

    try:
        result = retrieval_tool.invoke({"query": query})
        retrieval_results = str(result)

        tool_msg = ToolMessage(
            content=retrieval_results,
            tool_call_id=str(uuid.uuid4()),
            name="retrieval_tool",
        )

        messages = state.get("messages", [])
        messages.append(tool_msg)

        return {
            **state,
            "messages": messages,
            "retrieval_done": True,
            "retrieval_results": retrieval_results,
        }

    except Exception as e:
        print(f"retrieval error: {e}")
        return {
            **state,
            "retrieval_done": True,
            "retrieval_results": f"Error during retrieval: {str(e)}",
        }

def transform_query_node(state: AgentState) -> AgentState:
    print("Optimizing search query...")
    
    user_query = state["user_query"]
    web_results = state.get("web_search_results", "")
    iteration = state.get("iteration_count", 0)
    
    llm = _get_model()
    structured_llm = llm.with_structured_output(SearchQuery)

    if iteration == 0:
        system_prompt = "You are a search expert. Convert the user's question into a keyword-optimized search query for Google."
        user_prompt = f"User Question: {user_query}\n\nProvide the best search query."
    else:
        system_prompt = """You are a search expert. The previous search results were insufficient.
        Generate a NEW, DIFFERENT search query to find the missing information.
        Do not repeat the previous query."""
        user_prompt = f"""User Question: {user_query}
        Previous Search Query: {state.get('search_query', '')}
        Previous Search Results: {web_results}
        
        What should we search for next?"""

    try:
        result = structured_llm.invoke([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ])
        new_query = result.query
    except Exception:
        new_query = user_query 

    print(f"Generated Search Query: '{new_query}'")
    
    return {**state, "search_query": new_query}

def evaluate_retrieval_node(state: AgentState) -> AgentState:
    print("checking if knowledge base results are enough")
    retrieval_results = state.get("retrieval_results", "")
    query = state["user_query"]

    if not retrieval_results or len(retrieval_results) < 50:
        print("not enough info from knowledge base, will do web search")
        return {**state, "needs_web_search": True}

    llm = _get_model()

    try:
        structured_llm = llm.with_structured_output(GradeRetrieval)

        system_prompt = (
            "You are a grader assessing relevance of a retrieved document to a user question. "
            "If the document contains keywords or semantic meaning sufficient to answer the question, grade it as 'yes'. "
            "If the document is empty, irrelevant, or says 'information not found', grade it as 'no'."
        )

        grade_prompt = f"""Retrieved Documents:
{retrieval_results}

User Question:
{query}
"""

        scored_result = structured_llm.invoke(
            [SystemMessage(content=system_prompt), HumanMessage(content=grade_prompt)]
        )
        score = scored_result.score

    except Exception:
        print("could not use structured output, using simple yes/no check")
        prompt = f"""You are a grader.
Does the following document contain the answer to the question: "{query}"?
Document: {retrieval_results}

Respond with exactly one word: "yes" or "no".
"""
        response = llm.invoke(prompt)
        content = response.content.lower().strip()
        score = "yes" if "yes" in content else "no"

    print(f"grader decision: {score}")

    if score == "yes":
        print("knowledge base looks sufficient")
        return {**state, "needs_web_search": False}

    print("knowledge base is not enough, web search needed")
    return {**state, "needs_web_search": True}


def web_search_node(state: AgentState) -> AgentState:
    query = state.get("search_query", state["user_query"])
    
    print(f"Searching web for: {query}")
    
    iteration = state.get("iteration_count", 0)

    try:
        result = web_search_tool.invoke({"query": query})
        new_results = str(result)

        current_results = state.get("web_search_results", "")
        updated_results = f"{current_results}\n\n--- Search {iteration+1} ({query}) ---\n{new_results}"

        tool_msg = ToolMessage(
            content=new_results,
            tool_call_id=str(uuid.uuid4()),
            name="web_search",
        )
        messages = state.get("messages", [])
        messages.append(tool_msg)

        return {
            **state,
            "messages": messages,
            "web_search_done": True,
            "web_search_results": updated_results,
            "iteration_count": iteration + 1,
        }

    except Exception as e:
        print(f"Web search error: {e}")
        return {
            **state,
            "web_search_done": True,
            "iteration_count": iteration + 1,
        }

def evaluate_search_node(state: AgentState) -> AgentState:
    print("Checking if search results are sufficient")
    
    query = state["user_query"]
    web_results = state.get("web_search_results", "")
    iteration = state.get("iteration_count", 0)

    if iteration >= 5:
        print("Max iterations reached. Proceeding to generation.")
        return {**state, "needs_web_search": False}

    llm = _get_model()
    try:
        structured_llm = llm.with_structured_output(GradeRetrieval)
        
        system_prompt = """You are a research manager. 
        Decide if the search results gathered SO FAR are sufficient to answer the user's question strictly and accurately.
        If information is missing, answer 'yes' (we need more search).
        If sufficient, answer 'no' (stop searching)."""
        
        user_prompt = f"""User Question: {query}
        Current Search Results: {web_results}
        
        Do we need to search more?"""
        
        score = structured_llm.invoke([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]).score.lower()
        
    except Exception:
        score = "no"

    needs_more = "yes" in score
    print(f"Need more search? {'YES' if needs_more else 'NO'}")
    
    return {**state, "needs_web_search": needs_more}

def generate_response_node(state: AgentState) -> AgentState:
    print("generating final answer")
    llm = _get_model()

    context_parts = []
    if state.get("retrieval_results"):
        context_parts.append(f"=== Knowledge Base Results ===\n{state['retrieval_results']}\n")
    if state.get("web_search_results"):
        context_parts.append(f"=== Web Search Results ===\n{state['web_search_results']}\n")

    context = "\n".join(context_parts)

    system_prompt = """You are an agriculture expert assistant specialized in Indian farming conditions.

CRITICAL RULES:
1. You must use ONLY information explicitly provided in the context above.
2. You must use ONLY information relevant to INDIA.
3. If no India-specific information is found, state that clearly.
4. Plain text only (no markdown, no bullets).
5. The responses will be played back as an audio message to the user so keep it like a natural spoken response, without awkward pauses or unnatural phrasing.

ADDITIONAL AUDIO CLARITY RULES:
1. Do NOT use any symbols, formulas, chemical names, or abbreviations such as N, P, K, P2O5, K2O, kg/ha, hectare.
2. Always convert technical fertilizer terms into simple spoken language that a farmer can understand.
3. Explain nutrients using common fertilizer names like urea, DAP, and potash, not scientific nutrient codes.
4. Quantities must be explained in practical field terms, for example bags, handfuls, or simple numbers per acre.
5. Do NOT assume the listener knows science or chemistry.
6. Speak as if explaining to a farmer who has never gone to school.
7. The output must sound like a village agriculture officer speaking naturally, slowly, and clearly.
8. If a technical term cannot be simplified, explain it in one short sentence before using it.
9. Prefer simple conversational Indian English or local-language-style English suitable for audio playback.



"""

    user_prompt = f"""Based on the following context, answer this question about Indian agriculture:

{context}

Question: {state['user_query']}"""

    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
        structured_llm = llm.with_structured_output(LLMOutput)
        response = structured_llm.invoke(messages)
        final_response = response.content if hasattr(response, "content") else str(response)

        ai_msg = AIMessage(content=final_response.strip())
        state_messages = state.get("messages", [])
        state_messages.append(ai_msg)

        return {
            **state,
            "messages": state_messages,
            "final_response": final_response.strip(),
        }

    except Exception as e:
        print(f"response generation error: {e}")
        return {**state, "final_response": "I apologize, but I encountered an error while generating a response."}